{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "pursuant-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affecting-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r', encoding=\"utf8\") as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "activated-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word2vec = read_glove_vecs('data/glove.6B.200d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-scale",
   "metadata": {},
   "source": [
    "# Data Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "positive-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_data(filename):\n",
    "    file = open(filename, 'r')\n",
    "    data = file.read().lower()\n",
    "    file.close()\n",
    "\n",
    "    data = data.split('\\n')\n",
    "\n",
    "    pro_data = []\n",
    "    for sent in data:\n",
    "        pro_data.append(re.sub(r\"[^\\w\\s]\", '', sent))\n",
    "\n",
    "    return pro_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "thirty-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "# news_words = [w for w in brown.words(categories=['news']) if w.isalpha() and w not in stopwords]\n",
    "# new_data = [for sent.lower().split(\" \")  for sent in data]\n",
    "\n",
    "def remove_stopwords(data):\n",
    "    new_data = []\n",
    "\n",
    "    for sent in data:\n",
    "        temp = []\n",
    "        for word in sent.lower().split(' '):\n",
    "            if word not in stopwords:\n",
    "                temp.append(word)\n",
    "\n",
    "        new_data.append(temp)\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "def get_features(new_data):\n",
    "    X = []\n",
    "    for sent in new_data:\n",
    "        res = np.zeros(word2vec['word'].shape)\n",
    "        for word in sent:\n",
    "            try:\n",
    "                res += word2vec[word]\n",
    "            except:\n",
    "                res += 0\n",
    "        X.append(res)\n",
    "\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "painted-glossary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (10, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['links that provide communications between the tcs and other systems shall be secured in a manner appropriate for the sensitivities of the material passed through such links',\n",
       " 'the tcs shall be designed to protect its communication and data links against enemy electronic warfare ew threats physical antiradiation weaponry and physical destruction ',\n",
       " 'all hardware software documentation and sensitive information processed by tcs shall be physically protected minimally at the level determined by the risk index computed in section 381',\n",
       " 'the tcs shall be approved for operation at the same level as the systems with which it interfaces ',\n",
       " 'all tcs users operators maintainers and other personnel having access to tcs shall be cleared to the highest sensitivity of the data that the tcs processes stores and transfers ',\n",
       " 'additional local site procedures shall be developed to prevent the intentional or unintentional disclosure of sensitive information to unauthorized individuals ',\n",
       " 'a training program consisting of an initial security training and awareness briefing covering ais security in general but also tailored to the tcs shall be developed ',\n",
       " ' ',\n",
       " ' ',\n",
       " '']"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_and_clean_data(\"requirements/TCS/security.txt\")\n",
    "new_data = remove_stopwords(data)\n",
    "X = get_features(new_data)\n",
    "# new_data\n",
    "print(\"Shape of X:\", X.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-atmosphere",
   "metadata": {},
   "source": [
    "# Getting Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "interstate-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for sent1 in X:\n",
    "    res = []\n",
    "    for sent2 in X:\n",
    "        val = np.average(np.abs(sent1 - sent2))\n",
    "        res.append(round(val, 4))\n",
    "    result.append(res)\n",
    "    \n",
    "result = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "medical-roman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.7978</td>\n",
       "      <td>1.9392</td>\n",
       "      <td>1.3748</td>\n",
       "      <td>1.7191</td>\n",
       "      <td>1.6112</td>\n",
       "      <td>1.9574</td>\n",
       "      <td>1.8438</td>\n",
       "      <td>1.8438</td>\n",
       "      <td>1.8438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.7978</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.1838</td>\n",
       "      <td>2.1586</td>\n",
       "      <td>2.1594</td>\n",
       "      <td>2.0309</td>\n",
       "      <td>2.3445</td>\n",
       "      <td>2.6186</td>\n",
       "      <td>2.6186</td>\n",
       "      <td>2.6186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.9392</td>\n",
       "      <td>2.1838</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.0611</td>\n",
       "      <td>1.7317</td>\n",
       "      <td>1.9553</td>\n",
       "      <td>2.3729</td>\n",
       "      <td>2.6398</td>\n",
       "      <td>2.6398</td>\n",
       "      <td>2.6398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3748</td>\n",
       "      <td>2.1586</td>\n",
       "      <td>2.0611</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.6970</td>\n",
       "      <td>1.9703</td>\n",
       "      <td>2.0003</td>\n",
       "      <td>1.1386</td>\n",
       "      <td>1.1386</td>\n",
       "      <td>1.1386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.7191</td>\n",
       "      <td>2.1594</td>\n",
       "      <td>1.7317</td>\n",
       "      <td>1.6970</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.1275</td>\n",
       "      <td>2.3601</td>\n",
       "      <td>2.3995</td>\n",
       "      <td>2.3995</td>\n",
       "      <td>2.3995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.6112</td>\n",
       "      <td>2.0309</td>\n",
       "      <td>1.9553</td>\n",
       "      <td>1.9703</td>\n",
       "      <td>2.1275</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.1972</td>\n",
       "      <td>2.2872</td>\n",
       "      <td>2.2872</td>\n",
       "      <td>2.2872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.9574</td>\n",
       "      <td>2.3445</td>\n",
       "      <td>2.3729</td>\n",
       "      <td>2.0003</td>\n",
       "      <td>2.3601</td>\n",
       "      <td>2.1972</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.4348</td>\n",
       "      <td>2.4348</td>\n",
       "      <td>2.4348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.8438</td>\n",
       "      <td>2.6186</td>\n",
       "      <td>2.6398</td>\n",
       "      <td>1.1386</td>\n",
       "      <td>2.3995</td>\n",
       "      <td>2.2872</td>\n",
       "      <td>2.4348</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.8438</td>\n",
       "      <td>2.6186</td>\n",
       "      <td>2.6398</td>\n",
       "      <td>1.1386</td>\n",
       "      <td>2.3995</td>\n",
       "      <td>2.2872</td>\n",
       "      <td>2.4348</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.8438</td>\n",
       "      <td>2.6186</td>\n",
       "      <td>2.6398</td>\n",
       "      <td>1.1386</td>\n",
       "      <td>2.3995</td>\n",
       "      <td>2.2872</td>\n",
       "      <td>2.4348</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6       7       8  \\\n",
       "0  0.0000  1.7978  1.9392  1.3748  1.7191  1.6112  1.9574  1.8438  1.8438   \n",
       "1  1.7978  0.0000  2.1838  2.1586  2.1594  2.0309  2.3445  2.6186  2.6186   \n",
       "2  1.9392  2.1838  0.0000  2.0611  1.7317  1.9553  2.3729  2.6398  2.6398   \n",
       "3  1.3748  2.1586  2.0611  0.0000  1.6970  1.9703  2.0003  1.1386  1.1386   \n",
       "4  1.7191  2.1594  1.7317  1.6970  0.0000  2.1275  2.3601  2.3995  2.3995   \n",
       "5  1.6112  2.0309  1.9553  1.9703  2.1275  0.0000  2.1972  2.2872  2.2872   \n",
       "6  1.9574  2.3445  2.3729  2.0003  2.3601  2.1972  0.0000  2.4348  2.4348   \n",
       "7  1.8438  2.6186  2.6398  1.1386  2.3995  2.2872  2.4348  0.0000  0.0000   \n",
       "8  1.8438  2.6186  2.6398  1.1386  2.3995  2.2872  2.4348  0.0000  0.0000   \n",
       "9  1.8438  2.6186  2.6398  1.1386  2.3995  2.2872  2.4348  0.0000  0.0000   \n",
       "\n",
       "        9  \n",
       "0  1.8438  \n",
       "1  2.6186  \n",
       "2  2.6398  \n",
       "3  1.1386  \n",
       "4  2.3995  \n",
       "5  2.2872  \n",
       "6  2.4348  \n",
       "7  0.0000  \n",
       "8  0.0000  \n",
       "9  0.0000  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result)\n",
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "weighted-garden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "joined-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "clus = []\n",
    "for i in range(len(result)):\n",
    "    min_elm = 100000000000\n",
    "    idx_i = -1\n",
    "    idx_j = -1\n",
    "    \n",
    "    for j in range(len(result)):    \n",
    "        if(min_elm > result[i, j] and result[i, j] != 0):\n",
    "            min_elm = result[i, j]\n",
    "            idx_i = i\n",
    "            idx_j = j\n",
    "    \n",
    "    clus.append((min(idx_i, idx_j), max(idx_i, idx_j)))\n",
    "    \n",
    "clus = set(clus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "juvenile-manner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "links that provide communications between the tcs and other systems shall be secured in a manner appropriate for the sensitivities of the material passed through such links\n",
      "the tcs shall be designed to protect its communication and data links against enemy electronic warfare ew threats physical antiradiation weaponry and physical destruction \n",
      "\n",
      "all hardware software documentation and sensitive information processed by tcs shall be physically protected minimally at the level determined by the risk index computed in section 381\n",
      "all tcs users operators maintainers and other personnel having access to tcs shall be cleared to the highest sensitivity of the data that the tcs processes stores and transfers \n",
      "\n",
      "the tcs shall be approved for operation at the same level as the systems with which it interfaces \n",
      " \n",
      "\n",
      "the tcs shall be approved for operation at the same level as the systems with which it interfaces \n",
      "all tcs users operators maintainers and other personnel having access to tcs shall be cleared to the highest sensitivity of the data that the tcs processes stores and transfers \n",
      "\n",
      "the tcs shall be approved for operation at the same level as the systems with which it interfaces \n",
      " \n",
      "\n",
      "links that provide communications between the tcs and other systems shall be secured in a manner appropriate for the sensitivities of the material passed through such links\n",
      "the tcs shall be approved for operation at the same level as the systems with which it interfaces \n",
      "\n",
      "links that provide communications between the tcs and other systems shall be secured in a manner appropriate for the sensitivities of the material passed through such links\n",
      "a training program consisting of an initial security training and awareness briefing covering ais security in general but also tailored to the tcs shall be developed \n",
      "\n",
      "the tcs shall be approved for operation at the same level as the systems with which it interfaces \n",
      "\n",
      "\n",
      "links that provide communications between the tcs and other systems shall be secured in a manner appropriate for the sensitivities of the material passed through such links\n",
      "additional local site procedures shall be developed to prevent the intentional or unintentional disclosure of sensitive information to unauthorized individuals \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in clus:\n",
    "    print(data[item[0]])\n",
    "    print(data[item[1]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-survival",
   "metadata": {},
   "source": [
    "# Contradiction Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "macro-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd_model = load_model('contradiction_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "valued-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENT_SIZE = 40\n",
    "\n",
    "def convert_sent_to_emb(X, word_to_vec):\n",
    "    data = np.zeros((len(X), SENT_SIZE, len(word_to_vec['word'])))\n",
    "    \n",
    "    for i, sent in enumerate(X):\n",
    "        for j, word in enumerate(sent.split()):\n",
    "            try:\n",
    "                data[i, j, :] = word_to_vec[word]\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "polar-london",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Root</th>\n",
       "      <th>Antonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elongated</td>\n",
       "      <td>[stunted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thinskinned</td>\n",
       "      <td>[thickskinned]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tactful</td>\n",
       "      <td>[tactless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orphaned</td>\n",
       "      <td>[privileged]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>laconic</td>\n",
       "      <td>[glib,, garrulous,, talkative,, gossipy,, chat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Root                                            Antonym\n",
       "0    elongated                                          [stunted]\n",
       "1  thinskinned                                     [thickskinned]\n",
       "2      tactful                                         [tactless]\n",
       "3     orphaned                                       [privileged]\n",
       "4      laconic  [glib,, garrulous,, talkative,, gossipy,, chat..."
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ant = pd.read_csv('data/antonyms.txt', delimiter = '\\t')\n",
    "ant['Antonym'] = ant['Antonym'].str.split()\n",
    "\n",
    "words = ant['Root'].values\n",
    "ant_list = ant['Antonym'].values\n",
    "\n",
    "ant_dict = {}\n",
    "for word, ant_l in zip(words, ant_list):\n",
    "    ant_dict[word] = ant_l\n",
    "\n",
    "ant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "fatty-float",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_list(sent1, sent2):\n",
    "    l1 = sent1.lower().split()\n",
    "    l2 = sent2.lower().split()\n",
    "    return l1, l2\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(set(list1)) + len(set(list2))) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "negation_list = ['No', 'Not','None','No one','Nobody','Nothing','Neither','Nowhere','Never','Hardly','Scarcely','Barely','Doesn’t','Isn’t','Wasn’t','Shouldn’t','Wouldn’t','Couldn’t','Won’t','Can’t','Don’t']\n",
    "for i in range(len(negation_list)):\n",
    "    negation_list[i] = negation_list[i].lower().replace(\"’\", \"\")\n",
    "\n",
    "def isNegation(list1, list2, negation_list):\n",
    "    for word in list1:\n",
    "        if word in negation_list:\n",
    "            return True\n",
    "    \n",
    "    for word in list2:\n",
    "        if word in negation_list:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def get_antonyms(word, ant_dict):\n",
    "    ant = []\n",
    "    for s in wordnet.synsets(word):\n",
    "        for l in s.lemmas():\n",
    "            if l.antonyms():\n",
    "                ant.append(l.antonyms()[0].name())\n",
    "                \n",
    "    ans = list(set(ant))\n",
    "    if word in ant_dict:\n",
    "        ans.extend(ant_dict[word])\n",
    "        \n",
    "    return ans\n",
    "\n",
    "def isAntonym(sent1, sent2):\n",
    "    for w1 in sent1.split(' '):\n",
    "        for w2 in sent2.split(' '):\n",
    "            if w2 in get_antonyms(w1, ant_dict):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def is_numeric_mismatch(l1, l2):\n",
    "    for word1 in l1:\n",
    "        if word1.isnumeric():\n",
    "            for word2 in l2:\n",
    "                if word2.isnumeric() and word1 != word2:\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "primary-softball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tcs shall be approved for operation at the same level as the systems with which it interfaces \n",
      "all tcs users operators maintainers and other personnel having access to tcs shall be cleared to the highest sensitivity of the data that the tcs processes stores and transfers \n",
      "[0.2676113] Antonym \n",
      "\n",
      "links that provide communications between the tcs and other systems shall be secured in a manner appropriate for the sensitivities of the material passed through such links\n",
      "the tcs shall be approved for operation at the same level as the systems with which it interfaces \n",
      "Antonym \n",
      "\n",
      "Total Contradiction count : 1\n",
      "Total isAntonym count : 2\n",
      "Total Negation count : 0\n",
      "Total Numeric Mismatch count : 0\n"
     ]
    }
   ],
   "source": [
    "contra_count = 0\n",
    "isant_count = 0\n",
    "neg_count = 0\n",
    "isnum_count = 0\n",
    "\n",
    "for item in clus:\n",
    "    sent1 = data[item[0]]\n",
    "    sent2 = data[item[1]]\n",
    "    \n",
    "    l1, l2 = sent_to_list(sent1, sent2)\n",
    "    iou = jaccard_similarity(l1, l2)\n",
    "    neg = isNegation(l1, l2, negation_list)\n",
    "    isAnt = isAntonym(sent1, sent2)\n",
    "    isNum = is_numeric_mismatch(l1, l2)\n",
    "    \n",
    "    s1 = convert_sent_to_emb([sent1.lower()], word2vec)\n",
    "    s2 = convert_sent_to_emb([sent2.lower()], word2vec)\n",
    "    \n",
    "    pred = cd_model.predict([s1, s2, np.array([iou, neg, isAnt], dtype = float).reshape(1, 3)])\n",
    "    \n",
    "    if pred[0][0] < 0.5 or isAnt or neg or isNum:\n",
    "        print(sent1)\n",
    "        print(sent2)\n",
    "        if pred[0][0] < 0.5:\n",
    "            print(pred[0], end = ' ')\n",
    "            contra_count += 1\n",
    "        if isAnt:\n",
    "            print(\"Antonym\", end = ' ')\n",
    "            isant_count += 1\n",
    "        if neg:\n",
    "            print(\"Negation\", end = ' ')\n",
    "            neg_count += 1\n",
    "        if isNum:\n",
    "            print(\"Numeric Mistatch\")\n",
    "            isnum_count += 1\n",
    "        print(\"\\n\")\n",
    "        \n",
    "print(\"Total Contradiction count :\", contra_count)\n",
    "print(\"Total isAntonym count :\", isant_count)\n",
    "print(\"Total Negation count :\", neg_count)\n",
    "print(\"Total Numeric Mismatch count :\", isnum_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-remark",
   "metadata": {},
   "source": [
    "## Record\n",
    "CCNT:\n",
    "- Total : 10 + 5 + 10 + 6 + 50\n",
    "- Contradiction : 2 + 3 + 0 + 2 + 4\n",
    "- isAntonym : 0 + 1 + 0 + 0 + 3\n",
    "- Negation : 2 + 3 + 0 + 3 + 8\n",
    "- Numeric Mismatch : 0 + 0 + 0 + 2 + 1\n",
    "\n",
    "TCS:\n",
    "- Total : 11 + 42 + 18 + 10\n",
    "- Contradiction : 2 + 5 + 5 + 1\n",
    "- isAntonym : 1 + 0 + 1 + 2\n",
    "- Negation : 2 + 7 + 2 + 0\n",
    "- Numeric Mismatch : 0 + 0 + 1 + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-laser",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
